{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and display settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.10f' % x)\n",
    "\n",
    "import time, calendar\n",
    "import pytz, datetime\n",
    "from datetime import timedelta, datetime\n",
    "import sys, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the seed\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_version_major = int(tf.__version__.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf_version_major >= 2:\n",
    "    print ('Using tensorflow 2.x or greater')\n",
    "    tf.random.set_seed(2)\n",
    "else:\n",
    "    print ('Using tensorflow 1.x')\n",
    "    from tensorflow import set_random_seed\n",
    "    set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataset(dataframe, columns):\n",
    "    df = dataframe.copy()\n",
    "    for var in columns:\n",
    "        df[var] = np.log(df[var])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the original feature analysis was made in a separate Jupyter notebook. Below is just the summary of the results\n",
    "outliers=['ThreadsClient']\n",
    "target_var = 'TotalMessages'\n",
    "dropColumns=['LoopId', 'LoopStartTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the aggregated client side datasets\n",
    "summaryL1Z1 = pd.read_csv('summary-L1-zone1.csv')\n",
    "summaryL1Z2 = pd.read_csv('summary-L1-zone2.csv')\n",
    "summaryL2Z1 = pd.read_csv('summary-L2-zone1.csv')\n",
    "summaryL2Z2 = pd.read_csv('summary-L2-zone2.csv')\n",
    "summaryL3Z1 = pd.read_csv('summary-L3-zone1.csv')\n",
    "summaryL3Z2 = pd.read_csv('summary-L3-zone2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = summaryL1Z1.copy()\n",
    "allData = allData.append(summaryL1Z2)\n",
    "allData = allData.append(summaryL2Z1)\n",
    "allData = allData.append(summaryL2Z2)\n",
    "allData = allData.append(summaryL3Z1)\n",
    "allData = allData.append(summaryL3Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataCopy = allData.copy()\n",
    "allData = normalizeDataset(allData, outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRandomBaseline():\n",
    "    randomlist = []\n",
    "    for i in range(0, 30):\n",
    "        n = random.randint(0,len(allData)-1)\n",
    "        randomlist.append(n)\n",
    "    return randomlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractor of Kafka default values records\n",
    "def baselineValues(df):\n",
    "    return df[(df['BackgroundThreads']==10) & (df['NumNetworkThreads']==3) \n",
    "            & (df['NumIoThreads'] == 8) & (df['NumReplicaFetchers'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the baseline records from each summary dataset and concatenate them. \n",
    "# Note that baseline values are found only in Zone1 records\n",
    "baselinesDF_initial = baselineValues(summaryL1Z1)\n",
    "baselinesDF_initial = baselinesDF_initial.append(baselineValues(summaryL2Z1))\n",
    "baselinesDF_initial = baselinesDF_initial.append(baselineValues(summaryL3Z1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscalable_vars = dropColumns.copy()\n",
    "unscalable_vars.append(target_var)\n",
    "to_scale_vars = [var for var in allData.columns if var not in unscalable_vars]\n",
    "#to_scale_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTestDataset(scaler, targetColumnName, dropList, dataframe, outliersList):\n",
    "    df = dataframe.copy()\n",
    "    targetDF = df[[target_var]].reset_index(drop=True)\n",
    "    \n",
    "    df = df.drop(dropList, axis = 1)\n",
    "    df = pd.concat([df[[target_var]].reset_index(drop=True),\n",
    "                    pd.DataFrame(scaler.transform(df[to_scale_vars]), columns=to_scale_vars)],\n",
    "                    axis=1)\n",
    "    df = df.drop([targetColumnName], axis=1)\n",
    "    return (targetDF, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if activationToUse == 'GELU':\n",
    "    @tf.function\n",
    "    def custom_activation(x):\n",
    "        return 0.5*x*(1+tf.tanh(tf.sqrt(2/math.pi)*(x+0.044715*tf.pow(x, 3))))\n",
    "else:\n",
    "    custom_activation = 'relu'\n",
    "    \n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "get_custom_objects()['custom_activation'] = custom_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnList = allData.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-CPU",
   "language": "python",
   "name": "tf-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Nets imports\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten \n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, Adagrad, Adamax, SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CNN Model ##########\n",
    "def format_to_cnn(df):\n",
    "    X = np.expand_dims(df, axis=2)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verboseLevel=0\n",
    "validationSplit=0.2\n",
    "batchSize=30\n",
    "epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback preparation\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.5,\n",
    "                              patience=2,\n",
    "                              verbose=verboseLevel,\n",
    "                              mode='min',\n",
    "                              min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createReduceRLObject():\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.5,\n",
    "                              patience=2,\n",
    "                              verbose=verboseLevel,\n",
    "                              mode='min',\n",
    "                              min_lr=0.001)\n",
    "    return reduce_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = 9\n",
    "colList = ['HiddenLayers', 'R2Score', 'MAE', 'MSE', 'H5FileName', 'TrainHistory', 'TrainPredictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define CNN model\n",
    "    \n",
    "def cnn_model_mse(inputSize=inputSize):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=6, activation=custom_activation,\n",
    "                     #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                     #kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                     #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),                   \n",
    "                     input_shape=(inputSize,1)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, \n",
    "                     #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                     #kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                     #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),                   \n",
    "                     activation=custom_activation))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, \n",
    "                    #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                    #kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                    #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),                   \n",
    "                    activation=custom_activation))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(1, \n",
    "                    #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                    #kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                    #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),                   \n",
    "                    activation=\"linear\"))\n",
    "\n",
    "    optmzr=Adam(lr=0.001)\n",
    "    model.compile(optimizer=optmzr, loss='mse', metrics=['mse'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the datasets for LSTM processing\n",
    "cnn_X_test1_summaryL1Z2_std = format_to_cnn(X_test1_summaryL1Z2_std)\n",
    "cnn_X_test1_summaryL1Z2_minMax = format_to_cnn(X_test1_summaryL1Z2_minMax)\n",
    "cnn_X_train_base_std = format_to_cnn(X_train_base_std)\n",
    "cnn_X_train_base_minMax = format_to_cnn(X_train_base_minMax)\n",
    "cnn_X_train_all_std = format_to_cnn(X_train_all_std)\n",
    "cnn_X_train_all_minMax = format_to_cnn(X_train_all_minMax)\n",
    "cnn_X_test_all_std = format_to_cnn(X_test_all_std)\n",
    "cnn_X_test_all_minMax = format_to_cnn(X_test_all_minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax All MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_regr_minMax_all_mse = cnn_model_mse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cnn_minMax_all_mse = ModelCheckpoint(\"cnn_model_minMax_all_mse.h5\",\n",
    "                             monitor='val_loss',\n",
    "                             verbose=verboseLevel,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "reduce_lr_minMax_all_mse = createReduceRLObject()\n",
    "callbacks_list_cnn_minMax_all_mse = [checkpoint_cnn_minMax_all_mse, reduce_lr_minMax_all_mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_CNN_minMax_all_mse = cnn_regr_minMax_all_mse.fit(cnn_X_train_all_minMax, y_train_scaled_minMax_all,\n",
    "                            batch_size=30, \n",
    "                            validation_split=0.2, \n",
    "                            epochs=epochs, verbose=verboseLevel,\n",
    "                            callbacks=callbacks_list_cnn_minMax_all_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_regr_minMax_all_mse_new =load_model('cnn_model_minMax_all_mse.h5')\n",
    "#Predict\n",
    "y_pred_CNN_minMax_all_mse_scaled = cnn_regr_minMax_all_mse_new.predict(cnn_X_test_all_minMax)\n",
    "#reverse scaling to compare to true values\n",
    "pred = targetMinMaxScalerAll.inverse_transform(y_pred_CNN_minMax_all_mse_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if metrics.mean_absolute_error(y_test_all_minMax, pred) < minMaeAWS:\n",
    "minMseAWS = metrics.mean_squared_error(y_test_all_minMax, pred)\n",
    "minRmseAWS = np.sqrt(minMseAWS)\n",
    "minMaeAWS = metrics.mean_absolute_error(y_test_all_minMax, pred)\n",
    "minR2AWS = metrics.r2_score(y_test_all_minMax, pred)\n",
    "modelNameAWS = \"CNN_MinMax_ALL_MSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.DataFrame()\n",
    "delta = (1-(pd.DataFrame(pred)  / y_test_all_minMax.to_numpy()))*100\n",
    "delta = delta.rename(columns={delta.columns[0]: \"ThroughputDeltaDeviationPercentage\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_all = delta.median()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(test, pred):\n",
    "    x = 0\n",
    "    for i in range(len(test)):\n",
    "        x+=np.abs((test[test.columns[0]][i] - pred[i])/test[test.columns[0]][i])\n",
    "    return (x/len(test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_all = mape(y_test_all_minMax, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaeAWS, minR2AWS, modelNameAWS, minMseAWS, minRmseAWS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-CPU",
   "language": "python",
   "name": "tf-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

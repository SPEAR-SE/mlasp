{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM models\n",
    "# input shape format is [samples, timesteps, features]\n",
    "# base has [30, 1, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_lstm(df):\n",
    "    X = np.array(df)\n",
    "    return np.reshape(X, (X.shape[0], 1, X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the datasets for LSTM processing\n",
    "lstm_X_test1_summaryL1Z2_std = format_to_lstm(X_test1_summaryL1Z2_std)\n",
    "lstm_X_test1_summaryL1Z2_minMax = format_to_lstm(X_test1_summaryL1Z2_minMax)\n",
    "lstm_X_train_base_std = format_to_lstm(X_train_base_std)\n",
    "lstm_X_train_base_minMax = format_to_lstm(X_train_base_minMax)\n",
    "lstm_X_train_all_std = format_to_lstm(X_train_all_std)\n",
    "lstm_X_train_all_minMax = format_to_lstm(X_train_all_minMax)\n",
    "lstm_X_test_all_std = format_to_lstm(X_test_all_std)\n",
    "lstm_X_test_all_minMax = format_to_lstm(X_test_all_minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Nets imports\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten \n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, Adagrad, Adamax, SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define LSTM model\n",
    "#input shape for the LSTM is (number_steps x number_features)\n",
    "\n",
    "def lstm_model_mae(layerSize, numSteps, numFeatures):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(layerSize, return_sequences=True, input_shape=(numSteps,numFeatures),\n",
    "                    #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                    #kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                    #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),                   \n",
    "                   dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(LSTM(layerSize, input_shape=(numSteps,numFeatures), \n",
    "                    #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                    #kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                    #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),\n",
    "                   dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "    model.add(Dense(layerSize, kernel_initializer='normal',\n",
    "                    #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                    #kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                    #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),\n",
    "                    activation=custom_activation))\n",
    "    #model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='normal', \n",
    "                    #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                    #kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                    #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),\n",
    "                    activation='linear'))\n",
    "    \n",
    "    model.compile(Adam(lr=0.001),\n",
    "              loss='mae',\n",
    "              metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verboseLevel=0\n",
    "validationSplit=0.2\n",
    "batchSize=30\n",
    "epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback preparation\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.5,\n",
    "                              patience=2,\n",
    "                              verbose=verboseLevel,\n",
    "                              mode='min',\n",
    "                              min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerSize = 64\n",
    "numSteps = 1\n",
    "numFeatures = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STD ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_lstm_std_all_mae = ModelCheckpoint(\"lstm_model_std_all_mae.h5\",\n",
    "                             monitor='val_loss',\n",
    "                             verbose=verboseLevel,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "callbacks_list_lstm_std_all_mae = [checkpoint_lstm_std_all_mae, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_std_all_mae_model = lstm_model_mae(layerSize=layerSize, numSteps=numSteps, numFeatures=numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_LSTM_std_all_mae = lstm_std_all_mae_model.fit(lstm_X_train_all_std, y_train_scaled_std_all,\n",
    "                                batch_size=batchSize, \n",
    "                                validation_split=validationSplit, \n",
    "                                epochs=epochs, verbose=verboseLevel,\n",
    "                                callbacks=callbacks_list_lstm_std_all_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# LSTM STD ALL MAE\n",
    "#################################################\n",
    "#Reload the best saved model\n",
    "lstm_std_all_mae_model_new = load_model('lstm_model_std_all_mae.h5')\n",
    "#Predict\n",
    "y_pred_LSTM_std_all_mae = lstm_std_all_mae_model_new.predict(lstm_X_test_all_std)\n",
    "pred = targetStdScalerAll.inverse_transform(y_pred_LSTM_std_all_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMseAWS = metrics.mean_squared_error(y_test_all_std, pred)\n",
    "minRmseAWS = np.sqrt(minMseAWS)\n",
    "minMaeAWS = metrics.mean_absolute_error(y_test_all_std, pred)\n",
    "minR2AWS = metrics.r2_score(y_test_all_std, pred)\n",
    "modelNameAWS = \"LSTM_STD_ALL_MAE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.DataFrame()\n",
    "delta = (1-(pd.DataFrame(pred)  / y_test_all_std.to_numpy()))*100\n",
    "delta = delta.rename(columns={delta.columns[0]: \"ThroughputDeltaDeviationPercentage\"})\n",
    "#delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_all = delta.median()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(test, pred):\n",
    "    x = 0\n",
    "    for i in range(len(test)):\n",
    "        x+=np.abs((test[test.columns[0]][i] - pred[i])/test[test.columns[0]][i])\n",
    "    return (x/len(test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_all = mape(y_test_all_std, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaeAWS, minR2AWS, modelNameAWS, minMseAWS, minRmseAWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### END ####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-CPU",
   "language": "python",
   "name": "tf-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

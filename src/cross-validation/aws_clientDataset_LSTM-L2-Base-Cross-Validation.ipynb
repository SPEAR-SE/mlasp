{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM models\n",
    "# input shape format is [samples, timesteps, features]\n",
    "# base has [30, 1, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_lstm(df):\n",
    "    X = np.array(df)\n",
    "    return np.reshape(X, (X.shape[0], 1, X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the datasets for LSTM processing\n",
    "lstm_X_test1_summaryL1Z2_std = format_to_lstm(X_test1_summaryL1Z2_std)\n",
    "lstm_X_test1_summaryL1Z2_minMax = format_to_lstm(X_test1_summaryL1Z2_minMax)\n",
    "lstm_X_train_base_std = format_to_lstm(X_train_base_std)\n",
    "lstm_X_train_base_minMax = format_to_lstm(X_train_base_minMax)\n",
    "lstm_X_train_all_std = format_to_lstm(X_train_all_std)\n",
    "lstm_X_train_all_minMax = format_to_lstm(X_train_all_minMax)\n",
    "lstm_X_test_all_std = format_to_lstm(X_test_all_std)\n",
    "lstm_X_test_all_minMax = format_to_lstm(X_test_all_minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Nets imports\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten \n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, Adagrad, Adamax, SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define LSTM model\n",
    "#input shape for the LSTM is (number_steps x number_features)\n",
    "\n",
    "def lstm_model_mse(layerSize, numSteps, numFeatures):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(layerSize, return_sequences=True, input_shape=(numSteps,numFeatures),\n",
    "                    #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                    kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                    #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),                   \n",
    "                   dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(LSTM(layerSize, input_shape=(numSteps,numFeatures), \n",
    "                    #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                    kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                    #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),\n",
    "                   dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "    model.add(Dense(layerSize, kernel_initializer='normal',\n",
    "                    #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                    kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                    #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),\n",
    "                    activation=custom_activation))\n",
    "    #model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='normal', \n",
    "                    #kernel_regularizer=l1(0.01), bias_regularizer=l1(0.01),\n",
    "                    kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),\n",
    "                    #kernel_regularizer=l1_l2(0.01), bias_regularizer=l1_l2(0.01),\n",
    "                    activation='linear'))\n",
    "\n",
    "    model.compile(Adam(lr=0.001),\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verboseLevel=0\n",
    "validationSplit=0.2\n",
    "batchSize=30\n",
    "epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createReduceRLObject():\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.5,\n",
    "                              patience=2,\n",
    "                              verbose=verboseLevel,\n",
    "                              mode='min',\n",
    "                              min_lr=0.001)\n",
    "    return reduce_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerSize = 64\n",
    "numSteps = 1\n",
    "numFeatures = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### END ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is how to create multivariate time series with multiple steps from a single step multivariate series\n",
    "def format_to_lstm_nsteps(df_X, df_Y, n_steps=1):\n",
    "    X, y = list(), list()\n",
    "    df_X_a = df_X.to_numpy()\n",
    "    for i in range(len(df_X)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(df_X):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = df_X_a[i:end_ix, :]\n",
    "        seq_y = df_Y[end_ix-1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm3, y_train_lstm3 = format_to_lstm_nsteps(X_train_base_std, y_train_scaled_std_base,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm3_std_base_mse_model = lstm_model_mse(layerSize=layerSize, numSteps=3, numFeatures=numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_lstm3_std_base_mse = ModelCheckpoint(\"lstm3_model_std_base_mse_L2.h5\",\n",
    "                             monitor='val_loss',\n",
    "                             verbose=verboseLevel,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "reduce_lr_std_base_mse3 = createReduceRLObject()\n",
    "callbacks_list_lstm3_std_base_mse = [checkpoint_lstm3_std_base_mse, reduce_lr_std_base_mse3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_LSTM3_std_base_mse = lstm3_std_base_mse_model.fit(X_train_lstm3, y_train_lstm3,\n",
    "                                batch_size=5, \n",
    "                                validation_split=validationSplit, \n",
    "                                epochs=epochs, verbose=verboseLevel,\n",
    "                                callbacks=callbacks_list_lstm3_std_base_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lstm3, y_test_lstm3 = format_to_lstm_nsteps(X_test1_summaryL1Z2_std, y_test_scaled_std_base, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload the best saved model\n",
    "lstm3_std_base_mse_model_new = load_model('lstm3_model_std_base_mse_L2.h5')\n",
    "#Predict\n",
    "y_pred_LSTM_base_std_L1Z2_mse = lstm3_std_base_mse_model_new.predict(X_test_lstm3)\n",
    "pred = targetStdScalerBase.inverse_transform(y_pred_LSTM_base_std_L1Z2_mse)\n",
    "y_target = targetStdScalerBase.inverse_transform(y_test_lstm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMseAWS_base = metrics.mean_squared_error(y_target, pred)\n",
    "minRmseAWS_base = np.sqrt(minMseAWS_base)\n",
    "minMaeAWS_base = metrics.mean_absolute_error(y_target, pred)\n",
    "minR2AWS_base = metrics.r2_score(y_target, pred)\n",
    "modelNameAWS_base = \"LSTM3_STD_BASE_MSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.DataFrame()\n",
    "delta = (1-(pd.DataFrame(pred)  / pd.DataFrame(y_target)))*100\n",
    "delta = delta.rename(columns={delta.columns[0]: \"ThroughputDeltaDeviationPercentage\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd_base = delta.median()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(test, pred):\n",
    "    x = 0\n",
    "    for i in range(len(test)):\n",
    "        x+=np.abs((test[test.columns[0]][i] - pred[i])/test[test.columns[0]][i])\n",
    "    return (x/len(test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_base = np.mean(np.abs((y_target - pred) / y_target)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaeAWS_base, minR2AWS_base, modelNameAWS_base, minMseAWS_base, minRmseAWS_base"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-CPU",
   "language": "python",
   "name": "tf-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

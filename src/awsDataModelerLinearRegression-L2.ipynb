{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"minMaxScalerSetup.ipynb\"\n",
    "%run \"standardScalerSetup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel_base_STD = Ridge()\n",
    "linearModel_all_STD = Ridge()\n",
    "#linear_L1_model_STD = Lasso()\n",
    "#linear_L2_model_STD = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel_base_MinMax = Ridge()\n",
    "linearModel_all_MinMax = Ridge()\n",
    "#linear_L1_model_MinMax = Lasso()\n",
    "#linear_L2_model_MinMax = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel_base_STD.fit(X_train_base_std, y_train_base_std)\n",
    "#linear_L1_model_STD.fit(X_train_base_std, y_train_base_std)\n",
    "#linear_L2_model_STD.fit(X_train_base_std, y_train_base_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base_std = linearModel_base_STD.predict(X_test1_summaryL1Z2_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show results\n",
    "print(metrics.r2_score(y_test1_summaryL1Z2_std, y_pred_base_std))\n",
    "print(metrics.mean_absolute_error(y_test1_summaryL1Z2_std, y_pred_base_std))\n",
    "print(metrics.mean_squared_error(y_test1_summaryL1Z2_std, y_pred_base_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMseAWS_base = metrics.mean_squared_error(y_test1_summaryL1Z2_std, y_pred_base_std)\n",
    "minRmseAWS_base = np.sqrt(minMseAWS_base)\n",
    "minMaeAWS_base = metrics.mean_absolute_error(y_test1_summaryL1Z2_std, y_pred_base_std)\n",
    "minR2AWS_base = metrics.r2_score(y_test1_summaryL1Z2_std, y_pred_base_std)\n",
    "modelNameAWS_base = \"LinearRegressionL2_Base_Std\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction vs original\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(range(y_test1_summaryL1Z2_std.shape[0]),y_test1_summaryL1Z2_std,label=\"Original Data\", alpha=0.6, c='black')\n",
    "plt.scatter(range(y_pred_base_std.shape[0]),y_pred_base_std,label=\"Predicted Data\", \n",
    "            alpha=0.6, c='red')\n",
    "plt.ylabel('Total Messages')\n",
    "plt.xlabel('Records')\n",
    "plt.title('LinearRegression - L2 Base STD dataset prediction vs original')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.DataFrame()\n",
    "delta = (1-(pd.DataFrame(y_pred_base_std)  / y_test1_summaryL1Z2_std.to_numpy()))*100\n",
    "delta = delta.rename(columns={delta.columns[0]: \"Deviation (%)\"})\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta.min(), delta.max(), delta.mean(), delta.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = np.mean(np.abs((y_test1_summaryL1Z2_std.to_numpy() - y_pred_base_std) / y_test1_summaryL1Z2_std.to_numpy())) * 100\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = delta.plot(kind='box', fontsize=18, figsize=(6,8),\n",
    "             color=dict(boxes='black', whiskers='black', medians='black', caps='black'),\n",
    "             boxprops=dict(linestyle='-', linewidth=1.25),\n",
    "             #flierprops=dict(linestyle='-', linewidth=1.15),\n",
    "             medianprops=dict(linestyle='-', linewidth=1.15),\n",
    "             whiskerprops=dict(linestyle='-', linewidth=1.15),\n",
    "             capprops=dict(linestyle='-', linewidth=1.15),\n",
    "             showfliers=True, grid=False, rot=0)\n",
    "#ax.set_xlabel('Foo')\n",
    "#ax.set_ylabel('Bar in X')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta.plot.box(figsize=(6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = delta.plot.bar(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = delta.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, validation_scores = learning_curve(estimator=linearModel_base_STD, \n",
    "                                                              X=X_train_base_std,\n",
    "                                                             y=y_train_base_std,\n",
    "                                                             scoring=\"neg_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "validation_scores_mean = -validation_scores.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.plot(train_sizes,train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes,validation_scores_mean, label = 'Validation error')\n",
    "plt.title('Validation vs Train loss')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Train Sizes')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel_base_MinMax.fit(X_train_base_minMax, y_train_base_minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base_minMax = linearModel_base_MinMax.predict(X_test1_summaryL1Z2_minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show results\n",
    "print(metrics.r2_score(y_test1_summaryL1Z2_minMax, y_pred_base_minMax))\n",
    "print(metrics.mean_absolute_error(y_test1_summaryL1Z2_minMax, y_pred_base_minMax))\n",
    "print(metrics.mean_squared_error(y_test1_summaryL1Z2_minMax, y_pred_base_minMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if metrics.mean_absolute_error(y_test1_summaryL1Z2_minMax, y_pred_base_minMax) < minMaeAWS_base:\n",
    "    minMseAWS_base = metrics.mean_squared_error(y_test1_summaryL1Z2_minMax, y_pred_base_minMax)\n",
    "    minRmseAWS_base = np.sqrt(minMseAWS_base)\n",
    "    minMaeAWS_base = metrics.mean_absolute_error(y_test1_summaryL1Z2_minMax, y_pred_base_minMax)\n",
    "    minR2AWS_base = metrics.r2_score(y_test1_summaryL1Z2_minMax, y_pred_base_minMax)\n",
    "    modelNameAWS_base = \"LinearRegressionL2_Base_MinMax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.DataFrame()\n",
    "delta = (1-(pd.DataFrame(y_pred_base_minMax)  / y_test1_summaryL1Z2_minMax.to_numpy()))*100\n",
    "delta = delta.rename(columns={delta.columns[0]: \"Deviation (%)\"})\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = delta.plot(kind='box', fontsize=18, figsize=(6,8),\n",
    "             color=dict(boxes='black', whiskers='black', medians='black', caps='black'),\n",
    "             boxprops=dict(linestyle='-', linewidth=1.25),\n",
    "             #flierprops=dict(linestyle='-', linewidth=1.15),\n",
    "             medianprops=dict(linestyle='-', linewidth=1.15),\n",
    "             whiskerprops=dict(linestyle='-', linewidth=1.15),\n",
    "             capprops=dict(linestyle='-', linewidth=1.15),\n",
    "             showfliers=True, grid=False, rot=0)\n",
    "#ax.set_xlabel('Foo')\n",
    "#ax.set_ylabel('Bar in X')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta.min(), delta.max(), delta.mean(), delta.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction vs original\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(range(y_test1_summaryL1Z2_minMax.shape[0]),y_test1_summaryL1Z2_minMax,label=\"Original Data\", alpha=0.6, c='black')\n",
    "plt.scatter(range(y_pred_base_minMax.shape[0]),y_pred_base_minMax,label=\"Predicted Data\", \n",
    "            alpha=0.6, c='red')\n",
    "plt.ylabel('Total Messages')\n",
    "plt.xlabel('Records')\n",
    "plt.title('Linear Regression - L2 Base MinMax dataset prediction vs original')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, validation_scores = learning_curve(estimator=linearModel_base_MinMax, \n",
    "                                                              X=X_train_base_minMax,\n",
    "                                                             y=y_train_base_minMax,\n",
    "                                                             scoring=\"neg_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "validation_scores_mean = -validation_scores.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.plot(train_sizes,train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes,validation_scores_mean, label = 'Validation error')\n",
    "plt.title('Validation vs Train loss')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Train Sizes')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linearModel_all_STD.fit(X_train_all_std, y_train_all_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_all_std = linearModel_all_STD.predict(X_test_all_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show results\n",
    "print(metrics.r2_score(y_test_all_std, y_pred_all_std))\n",
    "print(metrics.mean_absolute_error(y_test_all_std, y_pred_all_std))\n",
    "print(metrics.mean_squared_error(y_test_all_std, y_pred_all_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMseAWS = metrics.mean_squared_error(y_test_all_std, y_pred_all_std)\n",
    "minRmseAWS = np.sqrt(minMseAWS)\n",
    "minMaeAWS = metrics.mean_absolute_error(y_test_all_std, y_pred_all_std)\n",
    "minR2AWS = metrics.r2_score(y_test_all_std, y_pred_all_std)\n",
    "modelNameAWS = \"LinearRegressionL2_All_Std\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction vs original\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(range(y_test_all_std.shape[0]),y_test_all_std,label=\"Original Data\", alpha=0.6, c='black')\n",
    "plt.scatter(range(y_pred_all_std.shape[0]),y_pred_all_std,label=\"Predicted Data\", \n",
    "            alpha=0.6, c='red')\n",
    "plt.ylabel('Total Messages')\n",
    "plt.xlabel('Records')\n",
    "plt.title('LinearRegression - L2 All STD dataset prediction vs original')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.DataFrame()\n",
    "delta = (1-(pd.DataFrame(y_pred_all_std)  / y_test_all_std.to_numpy()))*100\n",
    "delta = delta.rename(columns={delta.columns[0]: \"Deviation (%)\"})\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = delta.plot(kind='box', fontsize=18, figsize=(6,8),\n",
    "             color=dict(boxes='black', whiskers='black', medians='black', caps='black'),\n",
    "             boxprops=dict(linestyle='-', linewidth=1.25),\n",
    "             #flierprops=dict(linestyle='-', linewidth=1.15),\n",
    "             medianprops=dict(linestyle='-', linewidth=1.15),\n",
    "             whiskerprops=dict(linestyle='-', linewidth=1.15),\n",
    "             capprops=dict(linestyle='-', linewidth=1.15),\n",
    "             showfliers=True, grid=False, rot=0)\n",
    "#ax.set_xlabel('Foo')\n",
    "#ax.set_ylabel('Bar in X')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta.min(), delta.max(), delta.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = delta.plot.bar(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = delta.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, validation_scores = learning_curve(estimator=linearModel_all_STD, \n",
    "                                                              X=X_train_all_std,\n",
    "                                                             y=y_train_all_std,\n",
    "                                                             scoring=\"neg_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "validation_scores_mean = -validation_scores.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.plot(train_sizes,train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes,validation_scores_mean, label = 'Validation error')\n",
    "plt.title('Validation vs Train loss')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Train Sizes')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel_all_MinMax.fit(X_train_all_minMax, y_train_all_minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_all_minMax = linearModel_all_MinMax.predict(X_test_all_minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show results\n",
    "print(metrics.r2_score(y_test_all_minMax, y_pred_all_minMax))\n",
    "print(metrics.mean_absolute_error(y_test_all_minMax, y_pred_all_minMax))\n",
    "print(metrics.mean_squared_error(y_test_all_minMax, y_pred_all_minMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if metrics.mean_absolute_error(y_test_all_minMax, y_pred_all_minMax) < minMaeAWS :\n",
    "    minMseAWS = metrics.mean_squared_error(y_test_all_minMax, y_pred_all_minMax)\n",
    "    minRmseAWS = np.sqrt(minMseAWS)\n",
    "    minMaeAWS = metrics.mean_absolute_error(y_test_all_minMax, y_pred_all_minMax)\n",
    "    minR2AWS = metrics.r2_score(y_test_all_minMax, y_pred_all_minMax)\n",
    "    modelNameAWS = \"LinearRegressionL2_All_MinMax\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction vs original\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(range(y_test_all_minMax.shape[0]),y_test_all_minMax,label=\"Original Data\", alpha=0.6, c='black')\n",
    "plt.scatter(range(y_pred_all_minMax.shape[0]),y_pred_all_minMax,label=\"Predicted Data\", \n",
    "            alpha=0.6, c='red')\n",
    "plt.ylabel('Total Messages')\n",
    "plt.xlabel('Records')\n",
    "plt.title('LinearRegression - L2 All MinMax dataset prediction vs original')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.DataFrame()\n",
    "delta = (1-(pd.DataFrame(y_pred_all_minMax)  / y_test_all_minMax.to_numpy()))*100\n",
    "delta = delta.rename(columns={delta.columns[0]: \"Deviation (%)\"})\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = delta.plot(kind='box', fontsize=18, figsize=(6,8),\n",
    "             color=dict(boxes='black', whiskers='black', medians='black', caps='black'),\n",
    "             boxprops=dict(linestyle='-', linewidth=1.25),\n",
    "             #flierprops=dict(linestyle='-', linewidth=1.15),\n",
    "             medianprops=dict(linestyle='-', linewidth=1.15),\n",
    "             whiskerprops=dict(linestyle='-', linewidth=1.15),\n",
    "             capprops=dict(linestyle='-', linewidth=1.15),\n",
    "             showfliers=True, grid=False, rot=0)\n",
    "#ax.set_xlabel('Foo')\n",
    "#ax.set_ylabel('Bar in X')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta.min(), delta.max(), delta.mean(), delta.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = np.mean(np.abs((y_test_all_minMax.to_numpy() - y_pred_all_minMax) / y_test_all_minMax.to_numpy())) * 100\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(test, pred):\n",
    "    x = 0\n",
    "    for i in range(len(test)):\n",
    "        x+=np.abs((test['TotalMessages'][i] - pred[i])/test['TotalMessages'][i])\n",
    "    return(x/len(test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(y_test_all_minMax, y_pred_all_minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(y_test1_summaryL1Z2_std, y_pred_base_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta.plot.box(figsize=(6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, validation_scores = learning_curve(estimator=linearModel_all_MinMax, \n",
    "                                                              X=X_train_all_minMax,\n",
    "                                                             y=y_train_all_minMax,\n",
    "                                                             scoring=\"neg_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "validation_scores_mean = -validation_scores.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.plot(train_sizes,train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes,validation_scores_mean, label = 'Validation error')\n",
    "plt.title('Validation vs Train loss')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Train Sizes')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaeAWS, minR2AWS, modelNameAWS, minMseAWS, minRmseAWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaeAWS_base, minR2AWS_base, modelNameAWS_base, minMseAWS_base, minRmseAWS_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array([-27.175687,\n",
    "-5.879978,\n",
    "3.022724,\n",
    "1.30239,\n",
    "27.937123])).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-CPU",
   "language": "python",
   "name": "tf-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
